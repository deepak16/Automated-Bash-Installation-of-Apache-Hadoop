For Setting up HADOOP in the pseudo distributed mode(Single Node Cluster) , we need to modify 5 files
They are :
		a. bash.rc
		b. hadoop-env.sh
		c. core-site.xml
		d. mapred-site.xml.template
		e. hdfs-site.xml
		
		
		a. gedit ~/.bashrc
		
		We will append the lines below at the end of the bashrc file and then save it.

		#HADOOP VARIABLES START
		export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
		export HADOOP_INSTALL=/usr/local/hadoop
		export PATH=$PATH:$HADOOP_INSTALL/bin
		export PATH=$PATH:$HADOOP_INSTALL/sbin
		export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
		export HADOOP_COMMON_HOME=$HADOOP_INSTALL
		export HADOOP_HDFS_HOME=$HADOOP_INSTALL
		export YARN_HOME=$HADOOP_INSTALL
		export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native
		export HADOOP_OPTS="-Djava.library.path=$HADOOP_INSTALL/lib"
		#HADOOP VARIABLES END	
		
		b.  gedit /usr/local/hadoop/etc/hadoop/hadoop-env.sh
	
		Here , we open the hadoop-env.sh file  and change the value of JAVA_HOME variable to the path of our java.
		It is to be noted that java home can be different for differnt processors
		export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386 (can be "java-7-openjdk-amd64" for some other kind of processor)
		
		c. sudo mkdir -p /app/hadoop/tmp
	      sudo chown hduser:hadoop /app/hadoop/tmp
	      gedit /usr/local/hadoop/etc/hadoop/core-site.xml

		We add the configuration below between the to core-site.xml file between the configuration tags.

		<property>
  			<name>hadoop.tmp.dir</name>
        		<value>/app/hadoop/tmp</value>
            		<description>A base for other temporary directories.</description>
       </property>

 		<property>
  			<name>fs.default.name</name>
  			<value>hdfs://localhost:54310</value>
  			<description>The name of the default file system.  A URI whose
  			scheme and authority determine the FileSystem implementation.  The
  			uri's scheme determines the config property (fs.SCHEME.impl) naming
  			the FileSystem implementation class.  The uri's authority is used to
  			determine the host, port, etc. for a filesystem.</description>
 		</property>
 		
 		
		d.  cp /usr/local/hadoop/etc/hadoop/mapred-site.xml.template /usr/local/hadoop/etc/hadoop/mapred-site.xml
	       gedit /usr/local/hadoop/etc/hadoop/mapred-site.xml

			 We add the configuration below between the to mapred-site.xml file between the configuration tags.
		
	   <property>
  			<name>mapred.job.tracker</name>
  			<value>localhost:54311</value>
  			<description>The host and port that the MapReduce job tracker runs
  			at.  If "local", then jobs are run in-process as a single map
  			and reduce task.
  			</description>
 		</property>
 		
 		
 		
 		e.  sudo mkdir -p /usr/local/hadoop_store/hdfs/namenode
	       sudo mkdir -p /usr/local/hadoop_store/hdfs/datanode
	       sudo chown -R hduser:hadoop /usr/local/hadoop_store
	       gedit /usr/local/hadoop/etc/hadoop/hdfs-site.xml
	       
	       
	       We add the configuration below between the to hdfs-site.xml file between the configuration tags.
	       
	       
	   <property>
  			<name>dfs.replication</name>
  			<value>1</value>
  			<description>Default block replication.
  			The actual number of replications can be specified when the file is created.
  			The default is used if replication is not specified in create time.
  			</description>
 		</property>
 
 		<property>
   			<name>dfs.namenode.name.dir</name>
   			<value>file:/usr/local/hadoop_store/hdfs/namenode</value>
 		</property>
 
 		<property>
   			<name>dfs.datanode.data.dir</name>
   			<value>file:/usr/local/hadoop_store/hdfs/datanode</value>
 		</property>
 		
 		
 		
 		
